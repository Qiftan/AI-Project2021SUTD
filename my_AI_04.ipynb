{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.5 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "my-AI-01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "eb24ff17c96d57bb1b6bd790e601a0fc3cb43c71d84f2d33908d6829878e2da1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "import sys\r\n",
        "import os\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "import glob\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "outputs": [],
      "metadata": {
        "id": "Q9f8VOcgfSiC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "print(\"PyTorch version: \", torch.__version__)\r\n",
        "print(\"GPU Detected:\" ,torch.cuda.is_available())\r\n",
        "print(\"GPU Device Name:\", torch.cuda.get_device_name(0))\r\n",
        "\r\n",
        "#defining a shortcut function for later:\r\n",
        "# import os\r\n",
        "# using_GPU = os.path.exists('/opt/bin/nvidia-smi')\r\n",
        "\r\n",
        "using_GPU = torch.cuda.is_available()\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version:  1.9.0+cu102\n",
            "GPU Detected: True\n",
            "GPU Device Name: NVIDIA GeForce MX150\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqcRxwtaL0k5",
        "outputId": "af97adde-3d79-44aa-cd94-fda8f2661320"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Colab setup\n",
        "Run this only if you're training on colab. \n",
        "Make sure you have added the shared drive as a shortcut to the **root** of your google drive.\n",
        "\n",
        "If you're training your model offline and this cell throws `SyntaxError`, just ignore it."
      ],
      "metadata": {
        "id": "7zDsdEx7dAL5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "# currentlyRunningOnColab = 'google.colab' in sys.modules\r\n",
        "# if currentlyRunningOnColab:\r\n",
        "#   # Mount your own Google Drive\r\n",
        "#   from google.colab import drive\r\n",
        "#   drive.mount('/content/drive', force_remount=True)\r\n",
        "#   print(\"Mounted Google drive of current user\")\r\n",
        "\r\n",
        "#   %cd /content\r\n",
        "#   print(\"Changed current directory to /content\")\r\n",
        "\r\n",
        "#   # Mount github repository\r\n",
        "#   !git clone https://github.com/beazt123/AI-Project2021SUTD.git\r\n",
        "#   print(\"\\nCloned repo onto current instance of machine\")\r\n",
        "  \r\n",
        "#   %cd AI-Project2021SUTD\r\n",
        "#   print(\"\\nCurrently operating in the root directory of the Git repository\")\r\n",
        "\r\n",
        "#   # dataFolderName = \"aiproject\"\r\n",
        "#   GITHUB_REPO_NAME = \"AI-Project2021SUTD\"\r\n",
        "#   codePath = GITHUB_REPO_NAME\r\n",
        "#   # /content/drive/.shortcut-targets-by-id/1OU-Ua5tGwc7PDL_nf0s1CPKoIQduRW5q/50.021 AI Project"
      ],
      "outputs": [],
      "metadata": {
        "id": "oCXI27GDYmAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bb27842-5a5e-4cab-d73d-20d35e8c19a2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up the path where the data is stored\n",
        "Currently, this is set to an online directory. Change it if you're training it offline."
      ],
      "metadata": {
        "id": "akb3oVI5A8lY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "# # Change this variable if u wanna train offline\r\n",
        "# dataFolderPath = os.path.join(\"/content\",\r\n",
        "#                               \"drive\", \r\n",
        "#                               \".shortcut-targets-by-id\", \r\n",
        "#                               \"19icV-F9BFrur0fxo4XvAZ82qIhipVrb-\",\r\n",
        "#                               \"aiProjectData50021\")\r\n",
        "# # /content/drive/.shortcut-targets-by-id/19icV-F9BFrur0fxo4XvAZ82qIhipVrb-/aiProjectData50021"
      ],
      "outputs": [],
      "metadata": {
        "id": "1vUdlECEYwOK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "dataFolderPath = os.path.join(\"data2_1\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the data\n",
        "I'm assuming that the data is stored in the exact same structure as the one on our shared drive because the code in this section is written like that\n",
        "\n",
        "```\n",
        "dataFolder\n",
        "  |--COVID DATASET 1\n",
        "  |         |--someCSV.csv\n",
        "  |         |--anotherCSV.csv\n",
        "  |--COVID DATASET 2\n",
        "  |         |--someCSV2.csv\n",
        "  |         |--anotherCSV2.csv\n",
        "  |--COVID DATASET 3\n",
        "            |--someCSV3.csv\n",
        "            |--anotherCSV3.csv\n",
        "```"
      ],
      "metadata": {
        "id": "Qvtk6rmZV6qL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split into Training and Test sets"
      ],
      "metadata": {
        "id": "IVmc57I8DOvn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "trainingPercentage = 0.7\r\n",
        "testPercentage = 0.3"
      ],
      "outputs": [],
      "metadata": {
        "id": "yf032lccf7-d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "# folders = [\"COVID DATASET 1\",\"COVID DATASET 2\"]#, \"COVID DATASET 3\"]\r\n",
        "# csvLists = [glob.glob(f\"{dataFolderPath}/{folder}/*.csv\") for folder in folders]\r\n",
        "# csvLists = [glob.glob(f\"{dataFolderPath}/*.csv\")]\r\n",
        "folders = [\"data2_1\", \"data2_2\", \"data2_3\"]\r\n",
        "csvLists = [glob.glob(f\"{folder}/*.csv\") for folder in folders]"
      ],
      "outputs": [],
      "metadata": {
        "id": "yHYxJDtAXK2E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "# print(csvLists)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "overallTrain = []\r\n",
        "overallTest = []\r\n",
        "for csvList in csvLists:  \r\n",
        "  train, test = train_test_split(csvList,\r\n",
        "                                test_size=testPercentage,\r\n",
        "                                train_size=trainingPercentage)\r\n",
        "  overallTrain.extend(train)\r\n",
        "  overallTest.extend(test)"
      ],
      "outputs": [],
      "metadata": {
        "id": "ahCtqgkDWUGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define and fine tune the pre-process function\n",
        "Our dataset contains many columns we don't need"
      ],
      "metadata": {
        "id": "I_UloE4oDfhO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "def preProcessDataFrame(df: pd.DataFrame) -> pd.DataFrame:\r\n",
        "  \"\"\"\r\n",
        "  Takes in a dataframe and returns another dataframe that contains only the data we want.\r\n",
        "  Might wanna normalise the data as well\r\n",
        "  Maybe fill the nulls with zeros or other appropriate values.\r\n",
        "  \"\"\"\r\n",
        "  df_cp = df.copy()\r\n",
        "  \r\n",
        "#   df_cp.dropna(axis=0,\r\n",
        "#                how='any', \r\n",
        "#                subset=[\"username\", \"tweet id\"], \r\n",
        "#                inplace=True)\r\n",
        "  \r\n",
        "  df_cp = df_cp[[\"#followers\",\r\n",
        "                \"#friends\",\r\n",
        "                \"#retweets\",\r\n",
        "                \"#favorites\",\r\n",
        "                \"weekend\",\r\n",
        "                \"entity_count\",\r\n",
        "                \"hashtag_count\",\r\n",
        "                \"mention_count\",\r\n",
        "                \"url_count\",\r\n",
        "                \"tlen\",\r\n",
        "                \"ratio_fav_#followers\",\r\n",
        "                \"time_importance\",\r\n",
        "                \"sentiment_ppn\",\r\n",
        "                \"sine_hour\",\r\n",
        "                \"cosine_hour\",\r\n",
        "                \"sine_day\",\r\n",
        "                \"cosine_day\",\r\n",
        "                \"sine_day_of_week\",\r\n",
        "                \"cosine_day_of_week\"\r\n",
        "                ]]\r\n",
        "  return df_cp\r\n",
        "\r\n",
        "\r\n",
        "# sampleDf = pd.read_csv(overallTrain[0])\r\n",
        "sampleDf = pd.read_csv(f\"{dataFolderPath}/covid_data_1.csv\")\r\n",
        "# print(sampleDf.head())\r\n",
        "print(sampleDf.info())\r\n",
        "# [print(x) for x in sampleDf.columns] # show list of columns in sampleDf\r\n",
        "print(\"\\n====[AFTER PRE-PROCESSING]====\\n\")\r\n",
        "# print(preProcessDataFrame(sampleDf.head()))\r\n",
        "pp = preProcessDataFrame(sampleDf)\r\n",
        "print(pp.info())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 41 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Unnamed: 0            10000 non-null  int64  \n",
            " 1   tweet_id              10000 non-null  int64  \n",
            " 2   username              10000 non-null  object \n",
            " 3   timestamp             10000 non-null  object \n",
            " 4   #followers            10000 non-null  float64\n",
            " 5   #friends              10000 non-null  int64  \n",
            " 6   #retweets             10000 non-null  int64  \n",
            " 7   #favorites            10000 non-null  int64  \n",
            " 8   entities              10000 non-null  object \n",
            " 9   sentiment             10000 non-null  object \n",
            " 10  mentions              9984 non-null   object \n",
            " 11  hashtags              9998 non-null   object \n",
            " 12  urls                  10000 non-null  object \n",
            " 13  timeseg               10000 non-null  int64  \n",
            " 14  date                  10000 non-null  object \n",
            " 15  weekend               10000 non-null  int64  \n",
            " 16  entity_exist          10000 non-null  int64  \n",
            " 17  hashtag_exist         10000 non-null  int64  \n",
            " 18  mention_exist         10000 non-null  int64  \n",
            " 19  url_exist             10000 non-null  int64  \n",
            " 20  entity_count          10000 non-null  int64  \n",
            " 21  hashtag_count         10000 non-null  int64  \n",
            " 22  mention_count         10000 non-null  int64  \n",
            " 23  url_count             10000 non-null  int64  \n",
            " 24  tlen                  10000 non-null  int64  \n",
            " 25  ratio_fav_#followers  10000 non-null  float64\n",
            " 26  ratio_fri_#followers  10000 non-null  float64\n",
            " 27  time_importance       10000 non-null  int64  \n",
            " 28  year                  10000 non-null  int64  \n",
            " 29  day                   10000 non-null  int64  \n",
            " 30  month                 10000 non-null  int64  \n",
            " 31  day_of_week           10000 non-null  int64  \n",
            " 32  sentiment_p           10000 non-null  float64\n",
            " 33  sentiment_n           10000 non-null  float64\n",
            " 34  sentiment_ppn         10000 non-null  float64\n",
            " 35  sine_hour             10000 non-null  float64\n",
            " 36  cosine_hour           10000 non-null  float64\n",
            " 37  sine_day              10000 non-null  float64\n",
            " 38  cosine_day            10000 non-null  float64\n",
            " 39  sine_day_of_week      10000 non-null  float64\n",
            " 40  cosine_day_of_week    10000 non-null  float64\n",
            "dtypes: float64(12), int64(21), object(8)\n",
            "memory usage: 3.1+ MB\n",
            "None\n",
            "\n",
            "====[AFTER PRE-PROCESSING]====\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 19 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   #followers            10000 non-null  float64\n",
            " 1   #friends              10000 non-null  int64  \n",
            " 2   #retweets             10000 non-null  int64  \n",
            " 3   #favorites            10000 non-null  int64  \n",
            " 4   weekend               10000 non-null  int64  \n",
            " 5   entity_count          10000 non-null  int64  \n",
            " 6   hashtag_count         10000 non-null  int64  \n",
            " 7   mention_count         10000 non-null  int64  \n",
            " 8   url_count             10000 non-null  int64  \n",
            " 9   tlen                  10000 non-null  int64  \n",
            " 10  ratio_fav_#followers  10000 non-null  float64\n",
            " 11  time_importance       10000 non-null  int64  \n",
            " 12  sentiment_ppn         10000 non-null  float64\n",
            " 13  sine_hour             10000 non-null  float64\n",
            " 14  cosine_hour           10000 non-null  float64\n",
            " 15  sine_day              10000 non-null  float64\n",
            " 16  cosine_day            10000 non-null  float64\n",
            " 17  sine_day_of_week      10000 non-null  float64\n",
            " 18  cosine_day_of_week    10000 non-null  float64\n",
            "dtypes: float64(9), int64(10)\n",
            "memory usage: 1.4 MB\n",
            "None\n"
          ]
        }
      ],
      "metadata": {
        "id": "0-YOuMV6Zxgg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3a8308c-1bb9-4525-cde8-2d5f1a6a5e9d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "class TwitterDataset(Dataset):\r\n",
        "  def __init__(self, filenames, preProcessFunc = None):\r\n",
        "    # `filenames` is a list of strings the contains all file names.\r\n",
        "    # `batch_size` is the determines the number of files that we want to read in a chunk.\r\n",
        "        self.filenames = filenames\r\n",
        "        self.preProcess = preProcessFunc\r\n",
        "  def __len__(self):\r\n",
        "        return len(self.filenames)\r\n",
        "  def __getitem__(self, idx): #idx means index of the chunk.\r\n",
        "    # In this method, we do all the preprocessing.\r\n",
        "    # First read data from files in a chunk. Preprocess it. Extract labels. Then return data and labels.\r\n",
        "        csvFile = self.filenames[idx]\r\n",
        "        df = pd.read_csv(csvFile)\r\n",
        "        if self.preProcess:\r\n",
        "          df = self.preProcess(df)\r\n",
        "\r\n",
        "        x_arr = torch.Tensor(df.drop(columns=['#retweets']).to_numpy().astype(float))\r\n",
        "        y = torch.Tensor(df[\"#retweets\"].to_numpy().astype(float))\r\n",
        "        X = torch.squeeze( x_arr )\r\n",
        "        if idx == self.__len__():  \r\n",
        "          raise IndexError\r\n",
        "        return X, y\r\n",
        "  def sample_df(self, idx = 0):\r\n",
        "    return self[idx]"
      ],
      "outputs": [],
      "metadata": {
        "id": "fwu0jnghhZ_u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "source": [
        "train_loader = DataLoader(dataset = TwitterDataset(overallTrain, preProcessDataFrame),\r\n",
        "                            batch_size = 1,\r\n",
        "                            shuffle = True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "mHeuGojhkMFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the network\n",
        "Make sure this network takes in whatever input you give it and outputs a number. Alternative, if this is an immediate model, like the zero/more than zero retweets classifier, than train it and save the parameters externally. Then train the regressor in another copy of this script."
      ],
      "metadata": {
        "id": "fc_LITryyWzS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "source": [
        "class myNeuralNetwork(nn.Module): # Please change the name to your own network\r\n",
        "  def __init__(self, input_size):\r\n",
        "    super(myNeuralNetwork, self).__init__()\r\n",
        "\r\n",
        "    self.fc1 = nn.Linear(input_size, 2048)\r\n",
        "    self.fc2 = nn.Linear(2048, 512)\r\n",
        "    self.fc3 = nn.Linear(512, 128)\r\n",
        "    self.fc4 = nn.Linear(128, 1)\r\n",
        "    self.dropout = nn.Dropout(0.3)\r\n",
        "    self.nonlinearity = nn.ReLU()\r\n",
        "    self.batchnorm1 = nn.BatchNorm1d(2048)\r\n",
        "    self.batchnorm2 = nn.BatchNorm1d(512)\r\n",
        "    self.batchnorm3 = nn.BatchNorm1d(128)\r\n",
        "\r\n",
        "    pass\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "\r\n",
        "    x = self.dropout(F.relu(self.batchnorm1(self.fc1(x))))\r\n",
        "    x = self.dropout(F.relu(self.batchnorm2(self.fc2(x))))\r\n",
        "    x = self.dropout(F.relu(self.batchnorm3(self.fc3(x))))\r\n",
        "    x = F.relu(self.fc4(x))\r\n",
        "\r\n",
        "    return x\r\n",
        "\r\n",
        "class myNeuralNetwork2(nn.Module): # Please change the name to your own network\r\n",
        "  def __init__(self, input_size):\r\n",
        "    super(myNeuralNetwork2, self).__init__()\r\n",
        "\r\n",
        "    self.fc1 = nn.Linear(input_size, 256)\r\n",
        "    self.fc2 = nn.Linear(256, 64)\r\n",
        "    self.fc3 = nn.Linear(64, 64)\r\n",
        "    self.fc4 = nn.Linear(64, 1)\r\n",
        "    self.dropout = nn.Dropout(0.3)\r\n",
        "    self.nonlinearity = nn.ReLU()\r\n",
        "    self.batchnorm1 = nn.BatchNorm1d(256)\r\n",
        "    self.batchnorm2 = nn.BatchNorm1d(64)\r\n",
        "    self.batchnorm3 = nn.BatchNorm1d(64)\r\n",
        "\r\n",
        "    pass\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "\r\n",
        "    x = self.dropout(F.relu(self.batchnorm1(self.fc1(x))))\r\n",
        "    x = self.dropout(F.relu(self.batchnorm2(self.fc2(x))))\r\n",
        "    x = self.dropout(F.relu(self.batchnorm3(self.fc3(x))))\r\n",
        "    x = F.relu(self.fc4(x))\r\n",
        "\r\n",
        "    return x\r\n",
        "  "
      ],
      "outputs": [],
      "metadata": {
        "id": "sKpYd8cNwSRp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the network\n",
        "## Training parameters\n",
        "Choice of optimiser and loss and training params are entirely up to you"
      ],
      "metadata": {
        "id": "j4OyQtGUzK1R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "source": [
        "numEpochs = 10\r\n",
        "lr_rate = 1e-1\r\n",
        "\r\n",
        "input_size = 18\r\n",
        "\r\n",
        "b_size = 2500\r\n",
        "\r\n",
        "model = myNeuralNetwork(input_size)\r\n",
        "# model = myNeuralNetwork2(input_size)\r\n",
        "\r\n",
        "loss_function = nn.MSELoss() # Change to BCELoss for classification problem\r\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate, momentum=0.1)\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr_rate)"
      ],
      "outputs": [],
      "metadata": {
        "id": "4kAg-2nBv_dZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "source": [
        "if using_GPU:\r\n",
        "  model = model.cuda()\r\n",
        "\r\n",
        "# Check if the Module is on GPU by checking if a parameter is on GPU\r\n",
        "print(\"Model on GPU?:\")\r\n",
        "print(next(model.parameters()).is_cuda)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model on GPU?:\n",
            "True\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iamiSCWGNoAf",
        "outputId": "7394a08e-56c3-40d2-eede-c30820674a28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training for-loop"
      ],
      "metadata": {
        "id": "OqC5_j5tzOqv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "source": [
        "loss_lst = []\r\n",
        "\r\n",
        "for i in tqdm(range(numEpochs)):\r\n",
        "  for X_a, y_a in train_loader:\r\n",
        "    \r\n",
        "    X_a = torch.squeeze(X_a)\r\n",
        "    y_a = y_a.T\r\n",
        "\r\n",
        "    l = int(len(X_a)/b_size)\r\n",
        "\r\n",
        "    for m in range(l):\r\n",
        "      a = m*b_size\r\n",
        "      b = (m+1)*b_size-1\r\n",
        "\r\n",
        "      X = X_a[a:b]\r\n",
        "      y = y_a[a:b]\r\n",
        "\r\n",
        "      if using_GPU:\r\n",
        "        X = X.cuda()\r\n",
        "        y = y.cuda()\r\n",
        "\r\n",
        "      optimizer.zero_grad() \r\n",
        "      y_hat = model(X)\r\n",
        "      y_log = torch.log(y+1)\r\n",
        "      loss = loss_function(y_hat, y_log) #calculate the loss\r\n",
        "      loss.backward() #backprop\r\n",
        "      optimizer.step() #does the update\r\n",
        "\r\n",
        "  loss_lst.append(loss.cpu().data.numpy())\r\n",
        "  if i % 1 == 0:\r\n",
        "    print (\"Epoch: {0}, Loss: {1}, \".format(i, loss.cpu().data.numpy()))\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [07:47<00:00, 467.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 1.1767630577087402, \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dOXBluRjSbD",
        "outputId": "956e1980-9f4d-4d55-da7b-ce4ab464293a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.title(\"Training Loss\")\r\n",
        "plt.xlabel(\"Epochs\")\r\n",
        "plt.ylabel(\"Loss\")\r\n",
        "plt.plot(loss_lst)\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "source": [
        "# for i in tqdm(range(numEpochs)):\r\n",
        "#   for X, y in train_loader:\r\n",
        "\r\n",
        "#     X = torch.squeeze(X).cuda()\r\n",
        "#     y = y.T.cuda()\r\n",
        "\r\n",
        "#     y_hat = model(X)\r\n",
        "\r\n",
        "#     optimizer.zero_grad() \r\n",
        "#     y_hat = model(X)\r\n",
        "#     y_log = torch.log(y+1)\r\n",
        "#     loss = loss_function(y_hat, y_log) #calculate the loss\r\n",
        "#     loss.backward() #backprop\r\n",
        "#     optimizer.step() #does the update\r\n",
        "\r\n",
        "#   if i % 1 == 0:\r\n",
        "#       print (\"Epoch: {0}, Loss: {1}, \".format(i, loss.cpu().data.numpy()))"
      ],
      "outputs": [],
      "metadata": {
        "id": "jVxyBYuxmBr9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "source": [
        "# # init empty model\r\n",
        "# modelA = myNeuralNetwork(7)\r\n",
        "# optimizerA = torch.optim.Adam(modelA.parameters(), lr=0.01)\r\n",
        "\r\n",
        "# # load checkpoint from saved path\r\n",
        "# path = os.path.join(\"/content\",\r\n",
        "#                               \"drive\", \r\n",
        "#                               \".shortcut-targets-by-id\", \r\n",
        "#                               \"19icV-F9BFrur0fxo4XvAZ82qIhipVrb-\",\r\n",
        "#                               \"aiProjectData50021\",\r\n",
        "#                               \"models\",\r\n",
        "#                               \"model_20210729_1755_10epochs.pt\")\r\n",
        "# checkpoint = torch.load(path)\r\n",
        "\r\n",
        "# # load model\r\n",
        "# modelA.load_state_dict(checkpoint['model_state_dict'])\r\n",
        "# optimizerA.load_state_dict(checkpoint['optimizer_state_dict'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "h4ikmi0KEPNN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "source": [
        "# # torch.cuda.empty_cache()\r\n",
        "# if using_GPU:\r\n",
        "#   modelA = modelA.cuda()\r\n",
        "\r\n",
        "# # Check if the Module is on GPU by checking if a parameter is on GPU\r\n",
        "# print(\"Model on GPU?:\")\r\n",
        "# print(next(modelA.parameters()).is_cuda)"
      ],
      "outputs": [],
      "metadata": {
        "id": "FWZxhcCoFxt0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model"
      ],
      "metadata": {
        "id": "C7lgli26zSpf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "source": [
        "test_loader = DataLoader(dataset = TwitterDataset(overallTest, preProcessDataFrame),\r\n",
        "                            batch_size = 1,\r\n",
        "                            shuffle = True)\r\n",
        "model.eval()\r\n",
        "loss_lst_1 = []\r\n",
        "# cumLoss = 0\r\n",
        "for (i, (X, y)) in enumerate(test_loader):\r\n",
        "  X = torch.squeeze(X).cuda()\r\n",
        "  y = y.T.cuda()\r\n",
        "  y_hat = model(X)\r\n",
        "  y_log = torch.log(y+1)\r\n",
        "  # cum_loss += loss_fn(scores, labels).item()\r\n",
        "  loss = loss_function(y_hat, y_log)\r\n",
        "  loss_lst_1.append(loss.cpu().data.numpy())\r\n",
        "  # cumLoss += loss\r\n",
        "\r\n",
        "# print(f\"MSELoss: {cumLoss / len(test_loader)}\")\r\n",
        "print(f\"MSELoss: {loss}\")\r\n",
        "print(f\"Average MSELoss: {sum(loss_lst_1)/len(loss_lst_1)}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSELoss: 3.322397470474243\n",
            "Average MSELoss: 3.2079255561198083\n"
          ]
        }
      ],
      "metadata": {
        "id": "decLmbTQzVJr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "source": [
        "from datetime import datetime\r\n",
        "\r\n",
        "now = datetime.now()\r\n",
        "\r\n",
        "d4 = now.strftime(\"%Y%m%d_%H%M%S\")\r\n",
        "print(d4)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20210803_230703\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save your model"
      ],
      "metadata": {
        "id": "jqpz3C6iVlge"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "source": [
        "PATH = \"model_{0}.pt\".format(d4) #change this name to the name of your network\r\n",
        "\r\n",
        "torch.save({\r\n",
        "            'model_state_dict': model.state_dict(),\r\n",
        "            'optimizer_state_dict': optimizer.state_dict()\r\n",
        "            }, PATH)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Kw6rcOCiVk13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load model from elsewhere\n",
        "Just a reminder of how to load the model elsewhere after u save it. Also for me to deploy into the UI after you're done"
      ],
      "metadata": {
        "id": "25eRpxN3VyH2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "source": [
        "# # init empty model\r\n",
        "# modelA = NeuralNetwork()\r\n",
        "# optimModelA = optim.SGD(modelA.parameters(), lr=0.001, momentum=0.9)\r\n",
        "\r\n",
        "# # load checkpoint from saved path\r\n",
        "# checkpoint = torch.load(PATH)\r\n",
        "\r\n",
        "# # load model\r\n",
        "# modelA.load_state_dict(checkpoint['model_state_dict'])\r\n",
        "# optimizerA.load_state_dict(checkpoint['optimizer_state_dict'])\r\n",
        "\r\n",
        "# modelA.eval()\r\n",
        "# # - or -\r\n",
        "# modelA.train()"
      ],
      "outputs": [],
      "metadata": {
        "id": "bk9XhXs6V1Gk"
      }
    }
  ]
}