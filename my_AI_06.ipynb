{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.5 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "my-AI-01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "eb24ff17c96d57bb1b6bd790e601a0fc3cb43c71d84f2d33908d6829878e2da1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import sys\r\n",
        "import os\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "import glob\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "outputs": [],
      "metadata": {
        "id": "Q9f8VOcgfSiC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "print(\"PyTorch version: \", torch.__version__)\r\n",
        "print(\"GPU Detected:\" ,torch.cuda.is_available())\r\n",
        "print(\"GPU Device Name:\", torch.cuda.get_device_name(0))\r\n",
        "\r\n",
        "#defining a shortcut function for later:\r\n",
        "# import os\r\n",
        "# using_GPU = os.path.exists('/opt/bin/nvidia-smi')\r\n",
        "\r\n",
        "using_GPU = torch.cuda.is_available()\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version:  1.9.0+cu102\n",
            "GPU Detected: True\n",
            "GPU Device Name: NVIDIA GeForce MX150\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqcRxwtaL0k5",
        "outputId": "af97adde-3d79-44aa-cd94-fda8f2661320"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "dataFolderPath = os.path.join(\"data2_1\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "trainingPercentage = 0.7\r\n",
        "testPercentage = 0.3"
      ],
      "outputs": [],
      "metadata": {
        "id": "yf032lccf7-d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "folders = [\"data2_1\", \"data2_2\", \"data2_3\"]\r\n",
        "csvLists = [glob.glob(f\"{folder}/*.csv\") for folder in folders]"
      ],
      "outputs": [],
      "metadata": {
        "id": "yHYxJDtAXK2E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "# print(csvLists)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "overallTrain = []\r\n",
        "overallTest = []\r\n",
        "for csvList in csvLists:  \r\n",
        "  train, test = train_test_split(csvList,\r\n",
        "                                test_size=testPercentage,\r\n",
        "                                train_size=trainingPercentage)\r\n",
        "  overallTrain.extend(train)\r\n",
        "  overallTest.extend(test)"
      ],
      "outputs": [],
      "metadata": {
        "id": "ahCtqgkDWUGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define and fine tune the pre-process function\n",
        "Our dataset contains many columns we don't need"
      ],
      "metadata": {
        "id": "I_UloE4oDfhO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "def preProcessDataFrame(df: pd.DataFrame) -> pd.DataFrame:\r\n",
        "  \"\"\"\r\n",
        "  Takes in a dataframe and returns another dataframe that contains only the data we want.\r\n",
        "  Might wanna normalise the data as well\r\n",
        "  Maybe fill the nulls with zeros or other appropriate values.\r\n",
        "  \"\"\"\r\n",
        "  df_cp = df.copy()\r\n",
        "  \r\n",
        "#   df_cp.dropna(axis=0,\r\n",
        "#                how='any', \r\n",
        "#                subset=[\"username\", \"tweet id\"], \r\n",
        "#                inplace=True)\r\n",
        "  \r\n",
        "  df_cp = df_cp[[\"#followers\",\r\n",
        "                \"#friends\",\r\n",
        "                \"#retweets\",\r\n",
        "                \"#favorites\",\r\n",
        "                \"weekend\",\r\n",
        "                \"entity_count\",\r\n",
        "                \"hashtag_count\",\r\n",
        "                \"mention_count\",\r\n",
        "                \"url_count\",\r\n",
        "                \"tlen\",\r\n",
        "                \"ratio_fav_#followers\",\r\n",
        "                \"time_importance\",\r\n",
        "                \"sentiment_ppn\",\r\n",
        "                \"sine_hour\",\r\n",
        "                \"cosine_hour\",\r\n",
        "                \"sine_day\",\r\n",
        "                \"cosine_day\",\r\n",
        "                \"sine_day_of_week\",\r\n",
        "                \"cosine_day_of_week\"\r\n",
        "                ]]\r\n",
        "  return df_cp\r\n",
        "\r\n",
        "\r\n",
        "# sampleDf = pd.read_csv(overallTrain[0])\r\n",
        "sampleDf = pd.read_csv(f\"{dataFolderPath}/covid_data_1.csv\")\r\n",
        "# print(sampleDf.head())\r\n",
        "print(sampleDf.info())\r\n",
        "# [print(x) for x in sampleDf.columns] # show list of columns in sampleDf\r\n",
        "print(\"\\n====[AFTER PRE-PROCESSING]====\\n\")\r\n",
        "# print(preProcessDataFrame(sampleDf.head()))\r\n",
        "pp = preProcessDataFrame(sampleDf)\r\n",
        "print(pp.info())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 41 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Unnamed: 0            10000 non-null  int64  \n",
            " 1   tweet_id              10000 non-null  int64  \n",
            " 2   username              10000 non-null  object \n",
            " 3   timestamp             10000 non-null  object \n",
            " 4   #followers            10000 non-null  float64\n",
            " 5   #friends              10000 non-null  int64  \n",
            " 6   #retweets             10000 non-null  int64  \n",
            " 7   #favorites            10000 non-null  int64  \n",
            " 8   entities              10000 non-null  object \n",
            " 9   sentiment             10000 non-null  object \n",
            " 10  mentions              9984 non-null   object \n",
            " 11  hashtags              9998 non-null   object \n",
            " 12  urls                  10000 non-null  object \n",
            " 13  timeseg               10000 non-null  int64  \n",
            " 14  date                  10000 non-null  object \n",
            " 15  weekend               10000 non-null  int64  \n",
            " 16  entity_exist          10000 non-null  int64  \n",
            " 17  hashtag_exist         10000 non-null  int64  \n",
            " 18  mention_exist         10000 non-null  int64  \n",
            " 19  url_exist             10000 non-null  int64  \n",
            " 20  entity_count          10000 non-null  int64  \n",
            " 21  hashtag_count         10000 non-null  int64  \n",
            " 22  mention_count         10000 non-null  int64  \n",
            " 23  url_count             10000 non-null  int64  \n",
            " 24  tlen                  10000 non-null  int64  \n",
            " 25  ratio_fav_#followers  10000 non-null  float64\n",
            " 26  ratio_fri_#followers  10000 non-null  float64\n",
            " 27  time_importance       10000 non-null  int64  \n",
            " 28  year                  10000 non-null  int64  \n",
            " 29  day                   10000 non-null  int64  \n",
            " 30  month                 10000 non-null  int64  \n",
            " 31  day_of_week           10000 non-null  int64  \n",
            " 32  sentiment_p           10000 non-null  float64\n",
            " 33  sentiment_n           10000 non-null  float64\n",
            " 34  sentiment_ppn         10000 non-null  float64\n",
            " 35  sine_hour             10000 non-null  float64\n",
            " 36  cosine_hour           10000 non-null  float64\n",
            " 37  sine_day              10000 non-null  float64\n",
            " 38  cosine_day            10000 non-null  float64\n",
            " 39  sine_day_of_week      10000 non-null  float64\n",
            " 40  cosine_day_of_week    10000 non-null  float64\n",
            "dtypes: float64(12), int64(21), object(8)\n",
            "memory usage: 3.1+ MB\n",
            "None\n",
            "\n",
            "====[AFTER PRE-PROCESSING]====\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 19 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   #followers            10000 non-null  float64\n",
            " 1   #friends              10000 non-null  int64  \n",
            " 2   #retweets             10000 non-null  int64  \n",
            " 3   #favorites            10000 non-null  int64  \n",
            " 4   weekend               10000 non-null  int64  \n",
            " 5   entity_count          10000 non-null  int64  \n",
            " 6   hashtag_count         10000 non-null  int64  \n",
            " 7   mention_count         10000 non-null  int64  \n",
            " 8   url_count             10000 non-null  int64  \n",
            " 9   tlen                  10000 non-null  int64  \n",
            " 10  ratio_fav_#followers  10000 non-null  float64\n",
            " 11  time_importance       10000 non-null  int64  \n",
            " 12  sentiment_ppn         10000 non-null  float64\n",
            " 13  sine_hour             10000 non-null  float64\n",
            " 14  cosine_hour           10000 non-null  float64\n",
            " 15  sine_day              10000 non-null  float64\n",
            " 16  cosine_day            10000 non-null  float64\n",
            " 17  sine_day_of_week      10000 non-null  float64\n",
            " 18  cosine_day_of_week    10000 non-null  float64\n",
            "dtypes: float64(9), int64(10)\n",
            "memory usage: 1.4 MB\n",
            "None\n"
          ]
        }
      ],
      "metadata": {
        "id": "0-YOuMV6Zxgg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3a8308c-1bb9-4525-cde8-2d5f1a6a5e9d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "class TwitterDataset(Dataset):\r\n",
        "  def __init__(self, filenames, preProcessFunc = None):\r\n",
        "    # `filenames` is a list of strings the contains all file names.\r\n",
        "    # `batch_size` is the determines the number of files that we want to read in a chunk.\r\n",
        "        self.filenames = filenames\r\n",
        "        self.preProcess = preProcessFunc\r\n",
        "  def __len__(self):\r\n",
        "        return len(self.filenames)\r\n",
        "  def __getitem__(self, idx): #idx means index of the chunk.\r\n",
        "    # In this method, we do all the preprocessing.\r\n",
        "    # First read data from files in a chunk. Preprocess it. Extract labels. Then return data and labels.\r\n",
        "        csvFile = self.filenames[idx]\r\n",
        "        df = pd.read_csv(csvFile)\r\n",
        "        if self.preProcess:\r\n",
        "          df = self.preProcess(df)\r\n",
        "\r\n",
        "        x_arr = torch.Tensor(df.drop(columns=['#retweets']).to_numpy().astype(float))\r\n",
        "        y = torch.Tensor(df[\"#retweets\"].to_numpy().astype(float))\r\n",
        "        X = torch.squeeze( x_arr )\r\n",
        "        if idx == self.__len__():  \r\n",
        "          raise IndexError\r\n",
        "        return X, y\r\n",
        "  def sample_df(self, idx = 0):\r\n",
        "    return self[idx]"
      ],
      "outputs": [],
      "metadata": {
        "id": "fwu0jnghhZ_u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "train_loader = DataLoader(dataset = TwitterDataset(overallTrain, preProcessDataFrame),\r\n",
        "                            batch_size = 1,\r\n",
        "                            shuffle = True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "mHeuGojhkMFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the network\n",
        "Make sure this network takes in whatever input you give it and outputs a number. Alternative, if this is an immediate model, like the zero/more than zero retweets classifier, than train it and save the parameters externally. Then train the regressor in another copy of this script."
      ],
      "metadata": {
        "id": "fc_LITryyWzS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "class myNeuralNetwork(nn.Module): # Please change the name to your own network\r\n",
        "  def __init__(self, input_size):\r\n",
        "    super(myNeuralNetwork, self).__init__()\r\n",
        "\r\n",
        "    self.fc1 = nn.Linear(input_size, 2048)\r\n",
        "    self.fc2 = nn.Linear(2048, 512)\r\n",
        "    self.fc3 = nn.Linear(512, 128)\r\n",
        "    self.fc4 = nn.Linear(128, 1)\r\n",
        "    self.dropout = nn.Dropout(0.3)\r\n",
        "    self.nonlinearity = nn.ReLU()\r\n",
        "    self.batchnorm1 = nn.BatchNorm1d(2048)\r\n",
        "    self.batchnorm2 = nn.BatchNorm1d(512)\r\n",
        "    self.batchnorm3 = nn.BatchNorm1d(128)\r\n",
        "\r\n",
        "    pass\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "\r\n",
        "    x = self.dropout(F.relu(self.batchnorm1(self.fc1(x))))\r\n",
        "    x = self.dropout(F.relu(self.batchnorm2(self.fc2(x))))\r\n",
        "    x = self.dropout(F.relu(self.batchnorm3(self.fc3(x))))\r\n",
        "    x = F.relu(self.fc4(x))\r\n",
        "\r\n",
        "    return x\r\n",
        "\r\n",
        "class myNeuralNetwork2(nn.Module): # Please change the name to your own network\r\n",
        "  def __init__(self, input_size):\r\n",
        "    super(myNeuralNetwork2, self).__init__()\r\n",
        "\r\n",
        "    self.fc1 = nn.Linear(input_size, 256)\r\n",
        "    self.fc2 = nn.Linear(256, 64)\r\n",
        "    self.fc3 = nn.Linear(64, 64)\r\n",
        "    self.fc4 = nn.Linear(64, 1)\r\n",
        "    self.dropout = nn.Dropout(0.3)\r\n",
        "    self.nonlinearity = nn.ReLU()\r\n",
        "    self.batchnorm1 = nn.BatchNorm1d(256)\r\n",
        "    self.batchnorm2 = nn.BatchNorm1d(64)\r\n",
        "    self.batchnorm3 = nn.BatchNorm1d(64)\r\n",
        "\r\n",
        "    pass\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "\r\n",
        "    x = self.dropout(F.relu(self.batchnorm1(self.fc1(x))))\r\n",
        "    x = self.dropout(F.relu(self.batchnorm2(self.fc2(x))))\r\n",
        "    x = self.dropout(F.relu(self.batchnorm3(self.fc3(x))))\r\n",
        "    x = F.relu(self.fc4(x))\r\n",
        "\r\n",
        "    return x\r\n",
        "  "
      ],
      "outputs": [],
      "metadata": {
        "id": "sKpYd8cNwSRp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the network\n",
        "## Training parameters\n",
        "Choice of optimiser and loss and training params are entirely up to you"
      ],
      "metadata": {
        "id": "j4OyQtGUzK1R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "numEpochs = 5\r\n",
        "lr_rate = 1e-3\r\n",
        "\r\n",
        "input_size = 18\r\n",
        "\r\n",
        "# b_size = 1000\r\n",
        "\r\n",
        "model = myNeuralNetwork(input_size)\r\n",
        "# model = myNeuralNetwork2(input_size)\r\n",
        "\r\n",
        "loss_function = nn.MSELoss() # Change to BCELoss for classification problem\r\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)\r\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=lr_rate)"
      ],
      "outputs": [],
      "metadata": {
        "id": "4kAg-2nBv_dZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "if using_GPU:\r\n",
        "  model = model.cuda()\r\n",
        "\r\n",
        "# Check if the Module is on GPU by checking if a parameter is on GPU\r\n",
        "print(\"Model on GPU?:\")\r\n",
        "print(next(model.parameters()).is_cuda)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model on GPU?:\n",
            "True\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iamiSCWGNoAf",
        "outputId": "7394a08e-56c3-40d2-eede-c30820674a28"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=True)\r\n",
        "# https://ruder.io/optimizing-gradient-descent/"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training for-loop"
      ],
      "metadata": {
        "id": "OqC5_j5tzOqv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "loss_lst = []\r\n",
        "for i in tqdm(range(numEpochs)):\r\n",
        "  for X, y in train_loader:\r\n",
        "\r\n",
        "    X = torch.squeeze(X).cuda()\r\n",
        "    y = y.T.cuda()\r\n",
        "\r\n",
        "    optimizer.zero_grad() \r\n",
        "    y_hat = model(X)\r\n",
        "    y_log = torch.log(y+1)\r\n",
        "    loss = loss_function(y_hat, y_log) #calculate the loss\r\n",
        "    loss.backward() #backprop\r\n",
        "    optimizer.step() #does the update\r\n",
        "    \r\n",
        "  loss_lst.append(loss.cpu().data.numpy())\r\n",
        "  if i % 1 == 0:\r\n",
        "      print (\"Epoch: {0}, Loss: {1}, \".format(i, loss.cpu().data.numpy()))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 1/5 [06:30<26:01, 390.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 1.408220648765564, \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 2/5 [13:08<19:44, 394.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 1.0489988327026367, \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 3/5 [20:37<13:59, 419.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2, Loss: 0.7168951034545898, \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 4/5 [27:42<07:01, 421.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3, Loss: 0.7956587076187134, \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [34:34<00:00, 414.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4, Loss: 0.49519190192222595, \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "metadata": {
        "id": "jVxyBYuxmBr9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.title(\"Training Loss\")\r\n",
        "plt.xlabel(\"Epochs\")\r\n",
        "plt.ylabel(\"Loss\")\r\n",
        "plt.plot(loss_lst)\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model"
      ],
      "metadata": {
        "id": "C7lgli26zSpf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "test_loader = DataLoader(dataset = TwitterDataset(overallTest, preProcessDataFrame),\r\n",
        "                            batch_size = 1,\r\n",
        "                            shuffle = True)\r\n",
        "model.eval()\r\n",
        "loss_lst_1 = []\r\n",
        "# cumLoss = 0\r\n",
        "for (i, (X, y)) in enumerate(test_loader):\r\n",
        "  X = torch.squeeze(X).cuda()\r\n",
        "  y = y.T.cuda()\r\n",
        "  y_hat = model(X)\r\n",
        "  y_log = torch.log(y+1)\r\n",
        "  # cum_loss += loss_fn(scores, labels).item()\r\n",
        "  loss = loss_function(y_hat, y_log)\r\n",
        "  loss_lst_1.append(loss.cpu().data.numpy())\r\n",
        "  # cumLoss += loss\r\n",
        "\r\n",
        "# print(f\"MSELoss: {cumLoss / len(test_loader)}\")\r\n",
        "print(f\"MSELoss: {loss}\")\r\n",
        "print(f\"Average MSELoss: {sum(loss_lst_1)/len(loss_lst_1)}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSELoss: 0.9546071290969849\n",
            "Average MSELoss: 0.9292153011668812\n"
          ]
        }
      ],
      "metadata": {
        "id": "decLmbTQzVJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model_20210804_144105.pt ->\r\n",
        "MSELoss: 0.9546071290969849\r\n",
        "Average MSELoss: 0.9292153011668812\r\n",
        "\r\n",
        "model_20210804_175014.pt ->\r\n",
        "MSELoss: 0.8757791519165039\r\n",
        "Average MSELoss: 0.7937239170074463"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "numEpochs = 6\r\n",
        "lr_rate = 1e-3\r\n",
        "input_size = 18\r\n",
        "\r\n",
        "model = myNeuralNetwork(input_size)\r\n",
        "\r\n",
        "loss_function = nn.MSELoss()\r\n",
        "\r\n",
        "if using_GPU:\r\n",
        "  model = model.cuda()\r\n",
        "\r\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=True)\r\n",
        "\r\n",
        "loss_lst = []\r\n",
        "\r\n",
        "for i in tqdm(range(numEpochs)):\r\n",
        "  for X, y in train_loader:\r\n",
        "\r\n",
        "    X = torch.squeeze(X).cuda()\r\n",
        "    y = y.T.cuda()\r\n",
        "\r\n",
        "    optimizer.zero_grad() \r\n",
        "    y_hat = model(X)\r\n",
        "    y_log = torch.log(y+1)\r\n",
        "    loss = loss_function(y_hat, y_log) #calculate the loss\r\n",
        "    loss.backward() #backprop\r\n",
        "    optimizer.step() #does the update\r\n",
        "    \r\n",
        "  loss_lst.append(loss.cpu().data.numpy())\r\n",
        "  if i % 1 == 0:\r\n",
        "      print (\"Epoch: {0}, Loss: {1}, \".format(i, loss.cpu().data.numpy()))\r\n",
        "\r\n",
        "plt.title(\"Training Loss\")\r\n",
        "plt.xlabel(\"Epochs\")\r\n",
        "plt.ylabel(\"Loss\")\r\n",
        "plt.plot(loss_lst)\r\n",
        "plt.show()\r\n",
        "\r\n",
        "test_loader = DataLoader(dataset = TwitterDataset(overallTest, preProcessDataFrame),\r\n",
        "                            batch_size = 1,\r\n",
        "                            shuffle = True)\r\n",
        "model.eval()\r\n",
        "loss_lst_1 = []\r\n",
        "for (i, (X, y)) in enumerate(test_loader):\r\n",
        "  X = torch.squeeze(X).cuda()\r\n",
        "  y = y.T.cuda()\r\n",
        "  y_hat = model(X)\r\n",
        "  y_log = torch.log(y+1)\r\n",
        "  loss = loss_function(y_hat, y_log)\r\n",
        "  loss_lst_1.append(loss.cpu().data.numpy())\r\n",
        "print(f\"MSELoss: {loss}\")\r\n",
        "print(f\"Average MSELoss: {sum(loss_lst_1)/len(loss_lst_1)}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/8 [00:00<?, ?it/s]"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "numEpochs = 5\r\n",
        "lr_rate = 1e-4\r\n",
        "input_size = 18\r\n",
        "\r\n",
        "PATH = \"model_20210804_175014.pt\"\r\n",
        "\r\n",
        "# init empty model\r\n",
        "model = myNeuralNetwork(input_size)\r\n",
        "\r\n",
        "loss_function = nn.MSELoss() # Change to BCELoss for classification problem\r\n",
        "\r\n",
        "# load checkpoint from saved path\r\n",
        "checkpoint = torch.load(PATH)\r\n",
        "\r\n",
        "# load model\r\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\r\n",
        "\r\n",
        "if using_GPU:\r\n",
        "  model = model.cuda()\r\n",
        "\r\n",
        "# optimizer = torch.optim.AdamW(model.parameters(), lr=lr_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=True)\r\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\r\n",
        "\r\n",
        "# loss_lst = []\r\n",
        "\r\n",
        "# for i in tqdm(range(numEpochs)):\r\n",
        "#   for X, y in train_loader:\r\n",
        "\r\n",
        "#     X = torch.squeeze(X).cuda()\r\n",
        "#     y = y.T.cuda()\r\n",
        "\r\n",
        "#     optimizer.zero_grad() \r\n",
        "#     y_hat = model(X)\r\n",
        "#     y_log = torch.log(y+1)\r\n",
        "#     loss = loss_function(y_hat, y_log) #calculate the loss\r\n",
        "#     loss.backward() #backprop\r\n",
        "#     optimizer.step() #does the update\r\n",
        "    \r\n",
        "#   loss_lst.append(loss.cpu().data.numpy())\r\n",
        "#   if i % 1 == 0:\r\n",
        "#       print (\"Epoch: {0}, Loss: {1}, \".format(i, loss.cpu().data.numpy()))\r\n",
        "\r\n",
        "# plt.title(\"Training Loss\")\r\n",
        "# plt.xlabel(\"Epochs\")\r\n",
        "# plt.ylabel(\"Loss\")\r\n",
        "# plt.plot(loss_lst)\r\n",
        "# plt.show()\r\n",
        "\r\n",
        "test_loader = DataLoader(dataset = TwitterDataset(overallTest, preProcessDataFrame),\r\n",
        "                            batch_size = 1,\r\n",
        "                            shuffle = True)\r\n",
        "model.eval()\r\n",
        "loss_lst_1 = []\r\n",
        "for (i, (X, y)) in enumerate(test_loader):\r\n",
        "  X = torch.squeeze(X).cuda()\r\n",
        "  y = y.T.cuda()\r\n",
        "  y_hat = model(X)\r\n",
        "  y_log = torch.log(y+1)\r\n",
        "  loss = loss_function(y_hat, y_log)\r\n",
        "  loss_lst_1.append(loss.cpu().data.numpy())\r\n",
        "print(f\"MSELoss: {loss}\")\r\n",
        "print(f\"Average MSELoss: {sum(loss_lst_1)/len(loss_lst_1)}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:23<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-16-92f7b680ce48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumEpochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m   \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-9-f3652b6c5808>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# First read data from files in a chunk. Preprocess it. Extract labels. Then return data and labels.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mcsvFile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreProcess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m           \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1055\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1057\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2059\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2060\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2061\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2062\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "from datetime import datetime\r\n",
        "\r\n",
        "now = datetime.now()\r\n",
        "\r\n",
        "d4 = now.strftime(\"%Y%m%d_%H%M%S\")\r\n",
        "print(d4)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20210804_213338\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save your model"
      ],
      "metadata": {
        "id": "jqpz3C6iVlge"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "PATH = \"model_{0}.pt\".format(d4) #change this name to the name of your network\r\n",
        "\r\n",
        "torch.save({\r\n",
        "            'model_state_dict': model.state_dict(),\r\n",
        "            'optimizer_state_dict': optimizer.state_dict()\r\n",
        "            }, PATH)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Kw6rcOCiVk13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load model from elsewhere\n",
        "Just a reminder of how to load the model elsewhere after u save it. Also for me to deploy into the UI after you're done"
      ],
      "metadata": {
        "id": "25eRpxN3VyH2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "# PATH = \r\n",
        "\r\n",
        "# # init empty model\r\n",
        "# model = NeuralNetwork()\r\n",
        "# optimModel = optim.SGD(modelA.parameters(), lr=0.001, momentum=0.9)\r\n",
        "\r\n",
        "# # load checkpoint from saved path\r\n",
        "# checkpoint = torch.load(PATH)\r\n",
        "\r\n",
        "# # load model\r\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\r\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\r\n",
        "\r\n",
        "# # model.eval()\r\n",
        "# # - or -\r\n",
        "# model.train()"
      ],
      "outputs": [],
      "metadata": {
        "id": "bk9XhXs6V1Gk"
      }
    }
  ]
}